# âš™ï¸ Draftly â€” Backend

FastAPI + LangGraph multi-agent blog generation engine.

---

## ğŸš€ Setup

```bash
pip install -r requirements.txt
cp .env.example .env          # Add API keys
```

| Variable | Description |
|----------|-------------|
| `OPENROUTER_API_KEY` | LLM access via OpenRouter |
| `TAVILY_API_KEY` | Web research via Tavily |

## â–¶ï¸ Run

```bash
# API Server
uvicorn src.app:app --reload --port 8000

# CLI (standalone)
python -m src.main --topic "Your Topic" --platform medium
```

---

## ğŸ“¡ API

### `POST /generate-blog`

```json
{
  "topic": "Microservices Design Patterns",
  "platform": "medium",
  "enable_research": true
}
```

**Response:** `{ title, content, word_count, sections, platform, topic }`

### `GET /health` â†’ `{ "status": "ok" }`

---

## ğŸ§  Agent Flow

```
Router (Llama 3.3) â†’ Research (Tavily) â†’ Planner (Gemini 2.0) â†’ Workers (parallel) â†’ Merger
```

## ğŸ¯ Platforms

| Platform | Words | Tone |
|----------|-------|------|
| `generic` | 1500â€“2500 | Balanced |
| `medium` | 1500â€“3000 | Conversational |
| `devto` | 1000â€“2000 | Technical |
| `linkedin` | 800â€“1500 | Professional |

---

## ğŸ“ Structure

```
src/
â”œâ”€â”€ app.py            # FastAPI endpoints
â”œâ”€â”€ main.py           # CLI interface
â”œâ”€â”€ config.py         # Models, keys, platform settings
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ blog_agent.py # LangGraph workflow
â”‚   â””â”€â”€ llm_client.py # OpenRouter client (retry + fallback)
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ system_prompts.py
â””â”€â”€ utils/
    â””â”€â”€ helpers.py    # Logging, cache, file I/O
```
